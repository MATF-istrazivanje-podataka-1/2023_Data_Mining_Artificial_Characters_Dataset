{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1db06eb3",
   "metadata": {},
   "source": [
    "# K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932589f7",
   "metadata": {},
   "source": [
    "KNN stands for K-Nearest Neighbors and is a machine learning algorithm used for both classification and regression tasks. It is a non-parametric method, which means it does not make any assumptions about the underlying data distribution.\n",
    "\n",
    "In the KNN algorithm, a prediction is made for a new data point by finding the k nearest data points in the training set, where k is a user-defined hyperparameter. The prediction is based on the majority class (for classification) or the average value (for regression) of the k-nearest neighbors.\n",
    "\n",
    "The distance between data points is usually calculated using Euclidean distance, but other distance metrics can be used as well. KNN works well when the data has a simple structure and when the number of features is small, but can become computationally expensive as the dataset size and the number of features increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bd6b45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3f2fe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "834407ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = pd.read_csv('../../preprocessing/titles_preprocessed.csv')\n",
    "credits = pd.read_csv('../../preprocessing/credits_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95f73c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>release_year</th>\n",
       "      <th>runtime</th>\n",
       "      <th>genres</th>\n",
       "      <th>production_countries</th>\n",
       "      <th>seasons</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>imdb_score</th>\n",
       "      <th>imdb_votes</th>\n",
       "      <th>tmdb_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tm19248</td>\n",
       "      <td>The General</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>During America’s Civil War, Union spies steal ...</td>\n",
       "      <td>1926</td>\n",
       "      <td>78</td>\n",
       "      <td>['action', 'drama', 'war', 'western', 'comedy'...</td>\n",
       "      <td>['US']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tt0017925</td>\n",
       "      <td>8.2</td>\n",
       "      <td>89766.0</td>\n",
       "      <td>8.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tm83884</td>\n",
       "      <td>His Girl Friday</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>Hildy, the journalist former wife of newspaper...</td>\n",
       "      <td>1940</td>\n",
       "      <td>92</td>\n",
       "      <td>['comedy', 'drama', 'romance']</td>\n",
       "      <td>['US']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tt0032599</td>\n",
       "      <td>7.8</td>\n",
       "      <td>57835.0</td>\n",
       "      <td>11.270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tm19424</td>\n",
       "      <td>Detour</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>The life of Al Roberts, a pianist in a New Yor...</td>\n",
       "      <td>1945</td>\n",
       "      <td>66</td>\n",
       "      <td>['thriller', 'drama', 'crime']</td>\n",
       "      <td>['US']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tt0037638</td>\n",
       "      <td>7.3</td>\n",
       "      <td>17233.0</td>\n",
       "      <td>7.757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tm112005</td>\n",
       "      <td>Marihuana</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>A young girl named Burma attends a beach party...</td>\n",
       "      <td>1936</td>\n",
       "      <td>57</td>\n",
       "      <td>['crime', 'drama']</td>\n",
       "      <td>['US']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tt0026683</td>\n",
       "      <td>4.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>3.748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tm22806</td>\n",
       "      <td>Intolerance: Love's Struggle Throughout the Ages</td>\n",
       "      <td>MOVIE</td>\n",
       "      <td>The story of a poor young woman, separated by ...</td>\n",
       "      <td>1916</td>\n",
       "      <td>197</td>\n",
       "      <td>['history', 'drama']</td>\n",
       "      <td>['US']</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tt0006864</td>\n",
       "      <td>7.7</td>\n",
       "      <td>15242.0</td>\n",
       "      <td>9.412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             title   type   \n",
       "0   tm19248                                       The General  MOVIE  \\\n",
       "1   tm83884                                   His Girl Friday  MOVIE   \n",
       "2   tm19424                                            Detour  MOVIE   \n",
       "3  tm112005                                         Marihuana  MOVIE   \n",
       "4   tm22806  Intolerance: Love's Struggle Throughout the Ages  MOVIE   \n",
       "\n",
       "                                         description  release_year  runtime   \n",
       "0  During America’s Civil War, Union spies steal ...          1926       78  \\\n",
       "1  Hildy, the journalist former wife of newspaper...          1940       92   \n",
       "2  The life of Al Roberts, a pianist in a New Yor...          1945       66   \n",
       "3  A young girl named Burma attends a beach party...          1936       57   \n",
       "4  The story of a poor young woman, separated by ...          1916      197   \n",
       "\n",
       "                                              genres production_countries   \n",
       "0  ['action', 'drama', 'war', 'western', 'comedy'...               ['US']  \\\n",
       "1                     ['comedy', 'drama', 'romance']               ['US']   \n",
       "2                     ['thriller', 'drama', 'crime']               ['US']   \n",
       "3                                 ['crime', 'drama']               ['US']   \n",
       "4                               ['history', 'drama']               ['US']   \n",
       "\n",
       "   seasons    imdb_id  imdb_score  imdb_votes  tmdb_popularity  \n",
       "0      0.0  tt0017925         8.2     89766.0            8.647  \n",
       "1      0.0  tt0032599         7.8     57835.0           11.270  \n",
       "2      0.0  tt0037638         7.3     17233.0            7.757  \n",
       "3      0.0  tt0026683         4.0       864.0            3.748  \n",
       "4      0.0  tt0006864         7.7     15242.0            9.412  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17762727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bb6af9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm going to use the K Nearest Neighbours method to classify the credits (actors and directors) into different groups:\n",
    "# 1. High rated\n",
    "# 2. Medium rated\n",
    "# 3. Low rated\n",
    "# based on their TMDB popularity.\n",
    "# The ratings will be decided based on the average IMDB scores that each actors' movies/shows have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "997ad267",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>character</th>\n",
       "      <th>role</th>\n",
       "      <th>average_imdb_score</th>\n",
       "      <th>average_tmdb_popularity</th>\n",
       "      <th>imdb_score_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21174</td>\n",
       "      <td>tm19248</td>\n",
       "      <td>Buster Keaton</td>\n",
       "      <td>Johnny Gray</td>\n",
       "      <td>ACTOR</td>\n",
       "      <td>6.307692</td>\n",
       "      <td>4.784538</td>\n",
       "      <td>Medium-Rated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28713</td>\n",
       "      <td>tm19248</td>\n",
       "      <td>Marion Mack</td>\n",
       "      <td>Annabelle Lee</td>\n",
       "      <td>ACTOR</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>8.647000</td>\n",
       "      <td>High-Rated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28714</td>\n",
       "      <td>tm19248</td>\n",
       "      <td>Glen Cavender</td>\n",
       "      <td>Captain Anderson</td>\n",
       "      <td>ACTOR</td>\n",
       "      <td>7.400000</td>\n",
       "      <td>5.975500</td>\n",
       "      <td>High-Rated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28715</td>\n",
       "      <td>tm19248</td>\n",
       "      <td>Jim Farley</td>\n",
       "      <td>General Thatcher</td>\n",
       "      <td>ACTOR</td>\n",
       "      <td>6.033333</td>\n",
       "      <td>3.394500</td>\n",
       "      <td>Medium-Rated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27348</td>\n",
       "      <td>tm19248</td>\n",
       "      <td>Frederick Vroom</td>\n",
       "      <td>A Southern General</td>\n",
       "      <td>ACTOR</td>\n",
       "      <td>8.200000</td>\n",
       "      <td>8.647000</td>\n",
       "      <td>High-Rated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38898</th>\n",
       "      <td>321201</td>\n",
       "      <td>tm1055776</td>\n",
       "      <td>Piotr Trzaskalski</td>\n",
       "      <td>director</td>\n",
       "      <td>DIRECTOR</td>\n",
       "      <td>6.046369</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>Medium-Rated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38899</th>\n",
       "      <td>28071</td>\n",
       "      <td>tm975981</td>\n",
       "      <td>Cher</td>\n",
       "      <td>Herself</td>\n",
       "      <td>ACTOR</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>1.758000</td>\n",
       "      <td>High-Rated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38900</th>\n",
       "      <td>399383</td>\n",
       "      <td>tm975981</td>\n",
       "      <td>Nick Daley</td>\n",
       "      <td>Narrator</td>\n",
       "      <td>ACTOR</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>1.758000</td>\n",
       "      <td>High-Rated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38901</th>\n",
       "      <td>1032862</td>\n",
       "      <td>tm975981</td>\n",
       "      <td>Jonathan Finnigan</td>\n",
       "      <td>director</td>\n",
       "      <td>DIRECTOR</td>\n",
       "      <td>7.600000</td>\n",
       "      <td>1.758000</td>\n",
       "      <td>High-Rated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38905</th>\n",
       "      <td>2078564</td>\n",
       "      <td>tm1106415</td>\n",
       "      <td>Alex Gale</td>\n",
       "      <td>director</td>\n",
       "      <td>DIRECTOR</td>\n",
       "      <td>7.700000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>High-Rated</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38506 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       person_id         id               name           character      role   \n",
       "0          21174    tm19248      Buster Keaton         Johnny Gray     ACTOR  \\\n",
       "1          28713    tm19248        Marion Mack       Annabelle Lee     ACTOR   \n",
       "2          28714    tm19248      Glen Cavender    Captain Anderson     ACTOR   \n",
       "3          28715    tm19248         Jim Farley    General Thatcher     ACTOR   \n",
       "4          27348    tm19248    Frederick Vroom  A Southern General     ACTOR   \n",
       "...          ...        ...                ...                 ...       ...   \n",
       "38898     321201  tm1055776  Piotr Trzaskalski            director  DIRECTOR   \n",
       "38899      28071   tm975981               Cher             Herself     ACTOR   \n",
       "38900     399383   tm975981         Nick Daley            Narrator     ACTOR   \n",
       "38901    1032862   tm975981  Jonathan Finnigan            director  DIRECTOR   \n",
       "38905    2078564  tm1106415          Alex Gale            director  DIRECTOR   \n",
       "\n",
       "       average_imdb_score  average_tmdb_popularity imdb_score_bin  \n",
       "0                6.307692                 4.784538   Medium-Rated  \n",
       "1                8.200000                 8.647000     High-Rated  \n",
       "2                7.400000                 5.975500     High-Rated  \n",
       "3                6.033333                 3.394500   Medium-Rated  \n",
       "4                8.200000                 8.647000     High-Rated  \n",
       "...                   ...                      ...            ...  \n",
       "38898            6.046369                 0.898000   Medium-Rated  \n",
       "38899            7.600000                 1.758000     High-Rated  \n",
       "38900            7.600000                 1.758000     High-Rated  \n",
       "38901            7.600000                 1.758000     High-Rated  \n",
       "38905            7.700000                 0.600000     High-Rated  \n",
       "\n",
       "[38506 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing the data\n",
    "\n",
    "# Merge the titles with the actors/directors dataset\n",
    "merged_titles_credits = pd.merge(credits, titles, on='id', how='left')\n",
    "\n",
    "# Calculate the average IMDb score and TMDB popularity for each person_id\n",
    "person_scores_df = merged_titles_credits.groupby('person_id').agg({'imdb_score': 'mean', 'tmdb_popularity': 'mean'}).reset_index()\n",
    "person_scores_df.rename(columns={'imdb_score': 'average_imdb_score', 'tmdb_popularity': 'average_tmdb_popularity'}, inplace=True)\n",
    "\n",
    "# Merge the average IMDb scores with the actors/directors dataset\n",
    "merged_df = pd.merge(credits, person_scores_df, on='person_id', how='left')\n",
    "\n",
    "# Drop rows with missing average IMDb scores\n",
    "merged_df.dropna(subset=['average_imdb_score'], inplace=True)\n",
    "\n",
    "# Drop rows with missing average TMDB popularity\n",
    "merged_df.dropna(subset=['average_tmdb_popularity'], inplace=True)\n",
    "\n",
    "# IMDB score bins (0-4 - Low, 4-7 - Medium, 7-10 - High)\n",
    "bins = [0, 4, 7, 10]\n",
    "# Class labels\n",
    "labels = ['Low-Rated', 'Medium-Rated', 'High-Rated']  \n",
    "\n",
    "# Bin the IMDb scores into different ranges and assign labels\n",
    "merged_df['imdb_score_bin'] = pd.cut(merged_df['average_imdb_score'], bins=bins, labels=labels)\n",
    "\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1a3a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into features and target\n",
    "X = merged_df['average_tmdb_popularity'] # Features: TMDB popularity\n",
    "Y = merged_df['imdb_score_bin'] # Target: IMDb score bin from merged dataset\n",
    "\n",
    "# Splitting the data into testing and training sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88752313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12662     4.855000\n",
       "31356     6.336000\n",
       "37665     0.910000\n",
       "24266    10.365333\n",
       "3072      2.462667\n",
       "           ...    \n",
       "27264    29.006500\n",
       "31823     4.209000\n",
       "20541    16.285000\n",
       "935       2.200500\n",
       "34984     1.896000\n",
       "Name: average_tmdb_popularity, Length: 28879, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107c0b13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Normalizing TMDB popularity scores\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train.values.reshape(-1,1))\n",
    "\n",
    "X_train = scaler.transform(X_train.values.reshape(-1,1))\n",
    "X_test = scaler.transform(X_test.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4569ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de35094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for outliers\n",
    "from scipy import stats\n",
    "\n",
    "z_scores = stats.zscore(merged_df['average_tmdb_popularity'])\n",
    "outliers = merged_df[abs(z_scores) > 3]\n",
    "\n",
    "outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf47d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 230 is not that many instances compared to 38506 in total, so we will leave them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7155ede0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import classification_report\n",
    "from termcolor import colored\n",
    "\n",
    "def report(model, x, y, text = \"training\"):\n",
    "    y_pred = model.predict(x)\n",
    "    \n",
    "    print(colored(\"Classification report for model {} on {} data\".format(type(model).__name__, text), \"green\"))\n",
    "    print(\"---------------------------------------------------------------------------------\")\n",
    "    print(classification_report(y, y_pred, zero_division=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4a7df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Train the KNN classifier\n",
    "knn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893fdcdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting results \n",
    "Y_pred = knn.predict(X_test)\n",
    "\n",
    "# Evaluating the KNN model\n",
    "report(knn, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f3b5fe0",
   "metadata": {},
   "source": [
    "### Classification report - train set\n",
    "\n",
    "##### Precision: \n",
    "*true positives : (true positives + false positives)*\n",
    "\n",
    "* **High-Rated class** - 91% of the predicted High-Rated instances were actually High-Rated.\n",
    "* **Medium-Rated class** - 96% of the predicted Medium-Rated instances were actually Medium-Rated.\n",
    "* **Low-Rated class** - 84% of the predicted Low-Rated instances were actually Low-Rated.\n",
    "\n",
    "##### Recall\n",
    "*true positives : (true positives + false negatives)*\n",
    "\n",
    "* **High-Rated class** - The model correctly identified 87% of the actual High-Rated instances.\n",
    "* **Medium-Rated class** - The model correctly identified 97% of the actual Medium-Rated instances.\n",
    "* **Low-Rated class** - The model correctly identified 84% of the actual Low-Rated instances.\n",
    "\n",
    "##### F1-score\n",
    "*harmonic mean of precision and recall*\n",
    "\n",
    "* **High-Rated class** - 0.89\n",
    "* **Medium-Rated class** - 0.97\n",
    "* **Low-Rated class** - 0.84\n",
    "\n",
    "##### Support\n",
    "*the number of samples or instances of each class in the test dataset*\n",
    "\n",
    "* **High-Rated class** - 5065\n",
    "* **Medium-Rated class** - 22743\n",
    "* **Low-Rated class** - 1071\n",
    "\n",
    "\n",
    "### <u> Accuracy: 95% </u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776584d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "report(knn, X_test, Y_test, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e709b6c",
   "metadata": {},
   "source": [
    "### Classification report - test set\n",
    "\n",
    "##### Precision: \n",
    "*true positives : (true positives + false positives)*\n",
    "\n",
    "* **High-Rated class** - 85% of the predicted High-Rated instances were actually High-Rated.\n",
    "* **Medium-Rated class** - 95% of the predicted Medium-Rated instances were actually Medium-Rated.\n",
    "* **Low-Rated class** - 73% of the predicted Low-Rated instances were actually Low-Rated.\n",
    "\n",
    "##### Recall\n",
    "*true positives : (true positives + false negatives)*\n",
    "\n",
    "* **High-Rated class** - The model correctly identified 82% of the actual High-Rated instances.\n",
    "* **Medium-Rated class** - The model correctly identified 95% of the actual Medium-Rated instances.\n",
    "* **Low-Rated class** - The model correctly identified 81% of the actual Low-Rated instances.\n",
    "\n",
    "##### F1-score\n",
    "*harmonic mean of precision and recall*\n",
    "\n",
    "* **High-Rated class** - 0.83\n",
    "* **Medium-Rated class** - 0.95\n",
    "* **Low-Rated class** - 0.77\n",
    "\n",
    "##### Support\n",
    "*the number of samples or instances of each class in the test dataset*\n",
    "\n",
    "* **High-Rated class** - 1764\n",
    "* **Medium-Rated class** - 7527\n",
    "* **Low-Rated class** - 336\n",
    "\n",
    "\n",
    "### <u> Accuracy: 92% </u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e344896",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "# Create a heatmap for the confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrRd',\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87e7595",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d332d82d",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "##### For the Low-Rated class:\n",
    "* 1440 samples were correctly predicted as Low-Rated\n",
    "* 1 sample was predicted as Medium-Rated but was actually Low-Rated\n",
    "* 323 samples were predicted as High-Rated but were actually Low-Rated\n",
    "\n",
    "##### For the Medium-Rated class:\n",
    "* 3 samples were predicted as Low-Rated but were actually Medium-Rated\n",
    "* 273 samples were correctly predicted as Medium-Rated \n",
    "* 60 samples were predicted as High-Rated but were actually Medium-Rated \n",
    "\n",
    "##### For the High-Rated class:\n",
    "* 254 samples were predicted as Low-Rated but were actually High-Rated\n",
    "* 100 samples were predicted as Medium-Rated but were actually High-Rated\n",
    "* 7173 samples were correctly predicted as High-Rated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66ef733",
   "metadata": {},
   "source": [
    "# GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b854152",
   "metadata": {},
   "source": [
    "GridSearchCV is a technique for hyperparameter tuning in machine learning, which involves searching for the best set of hyperparameters that result in the optimal performance of a model.\n",
    "\n",
    "In GridSearchCV, a set of hyperparameters and their respective values are predefined, and the algorithm evaluates the performance of the model for each combination of these hyperparameters. The evaluation is typically done using cross-validation, where the dataset is split into several folds, and the model is trained on a portion of the data and tested on the remaining part. This helps to avoid overfitting and provides a more reliable estimate of the model's performance.\n",
    "\n",
    "GridSearchCV exhaustively searches over all the possible hyperparameter combinations, and returns the combination that produces the best performance on the validation data. The performance metric used for evaluation can be specified by the user, and can vary depending on the problem at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4570ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gini: measures impurity by calculating the probability of misclassifying a randomly chosen data point in that node\n",
    "# entropy: measures impurity by calculating the entropy of the class\n",
    "# This model will try both criterions to decide on how to split the decision tree\n",
    "\n",
    "# The grid search will also try different values of the maximum depth of the decision tree (2, 4, 6, 8)\n",
    "params = {'criterion': ['gini', 'entropy'], \n",
    "          'max_depth': [2, 4, 6, 8]\n",
    "         }\n",
    "\n",
    "params_grid = {'n_neighbors': range(10, 50, 5),\n",
    "               'weights': ['uniform', 'distance'],\n",
    "                'p': [1, 2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ef41ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "estimator = GridSearchCV(KNeighborsClassifier(), params_grid, cv=6, verbose=4)\n",
    "estimator.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90e7542",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = estimator.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c2cf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what the best parameters are based on the estimator:\n",
    "\n",
    "estimator.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f596432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about the best score?\n",
    "\n",
    "estimator.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69753fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "report(estimator.best_estimator_, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f5d8c3",
   "metadata": {},
   "source": [
    "### Classification report - train set\n",
    "\n",
    "##### Precision: \n",
    "*true positives : (true positives + false positives)*\n",
    "\n",
    "* **High-Rated class** - 99% of the predicted High-Rated instances were actually High-Rated.\n",
    "* **Medium-Rated class** - 99% of the predicted Medium-Rated instances were actually Medium-Rated.\n",
    "* **Low-Rated class** - 90% of the predicted Low-Rated instances were actually Low-Rated.\n",
    "\n",
    "##### Recall\n",
    "*true positives : (true positives + false negatives)*\n",
    "\n",
    "* **High-Rated class** - The model correctly identified 98% of the actual High-Rated instances.\n",
    "* **Medium-Rated class** - The model correctly identified 99% of the actual Medium-Rated instances.\n",
    "* **Low-Rated class** - The model correctly identified 95% of the actual Low-Rated instances.\n",
    "\n",
    "##### F1-score\n",
    "*harmonic mean of precision and recall*\n",
    "\n",
    "* **High-Rated class** - 0.98\n",
    "* **Medium-Rated class** - 0.99\n",
    "* **Low-Rated class** - 0.92\n",
    "\n",
    "##### Support\n",
    "*the number of samples or instances of each class in the test dataset*\n",
    "\n",
    "* **High-Rated class** - 5065\n",
    "* **Medium-Rated class** - 22743\n",
    "* **Low-Rated class** - 1071\n",
    "\n",
    "\n",
    "### <u> Accuracy: 99% </u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f486b1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "report(estimator.best_estimator_, X_test, Y_test, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b413d985",
   "metadata": {},
   "source": [
    "### Classification report - test set\n",
    "\n",
    "##### Precision: \n",
    "*true positives : (true positives + false positives)*\n",
    "\n",
    "* **High-Rated class** - 96% of the predicted High-Rated instances were actually High-Rated.\n",
    "* **Medium-Rated class** - 98% of the predicted Medium-Rated instances were actually Medium-Rated.\n",
    "* **Low-Rated class** - 85% of the predicted Low-Rated instances were actually Low-Rated.\n",
    "\n",
    "##### Recall\n",
    "*true positives : (true positives + false negatives)*\n",
    "\n",
    "* **High-Rated class** - The model correctly identified 94% of the actual High-Rated instances.\n",
    "* **Medium-Rated class** - The model correctly identified 98% of the actual Medium-Rated instances.\n",
    "* **Low-Rated class** - The model correctly identified 89% of the actual Low-Rated instances.\n",
    "\n",
    "##### F1-score\n",
    "*harmonic mean of precision and recall*\n",
    "\n",
    "* **High-Rated class** - 0.95\n",
    "* **Medium-Rated class** - 0.98\n",
    "* **Low-Rated class** - 0.87\n",
    "\n",
    "##### Support\n",
    "*the number of samples or instances of each class in the test dataset*\n",
    "\n",
    "* **High-Rated class** - 1764\n",
    "* **Medium-Rated class** - 7527\n",
    "* **Low-Rated class** - 336\n",
    "\n",
    "\n",
    "### <u> Accuracy: 97% </u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5760fdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "# Class labels\n",
    "labels = ['Low-Rated', 'Medium-Rated', 'High-Rated']  \n",
    "\n",
    "# Create a heatmap for the confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrRd',\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3d328e",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "##### For the Low-Rated class:\n",
    "* 1661 samples were correctly predicted as Low-Rated\n",
    "* 0 samples were predicted as Medium-Rated but were actually Low-Rated\n",
    "* 103 samples were predicted as High-Rated but were actually Low-Rated\n",
    "\n",
    "##### For the Medium-Rated class:\n",
    "* 2 samples were predicted as Low-Rated but were actually Medium-Rated\n",
    "* 299 samples were correctly predicted as Medium-Rated \n",
    "* 35 samples were predicted as High-Rated but were actually Medium-Rated \n",
    "\n",
    "##### For the High-Rated class:\n",
    "* 72 samples were predicted as Low-Rated but were actually High-Rated\n",
    "* 52 samples were predicted as Medium-Rated but were actually High-Rated\n",
    "* 7403 samples were correctly predicted as High-Rated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7491eac8",
   "metadata": {},
   "source": [
    "# Bagging Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16efa15",
   "metadata": {},
   "source": [
    "The bagging classifier, also known as bootstrap aggregating, is a type of ensemble learning algorithm that combines multiple decision tree models to improve the overall performance of the classification task. Bagging works by creating multiple subsets of the original training data set by randomly selecting observations with replacement, and training a separate decision tree model on each of these subsets.\n",
    "\n",
    "During the prediction phase, each decision tree model produces its own classification result, and the final classification is determined by aggregating the results of all the individual models. This aggregation can be done by taking the majority vote, where the classification with the most votes is chosen as the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1c80fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "baggingKNN = BaggingClassifier(estimator=KNeighborsClassifier(), n_estimators=20)\n",
    "baggingKNN.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fb51b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = baggingKNN.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584c225d",
   "metadata": {},
   "outputs": [],
   "source": [
    "report(baggingKNN, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d50bf84",
   "metadata": {},
   "source": [
    "### Classification report - train set\n",
    "\n",
    "##### Precision: \n",
    "*true positives : (true positives + false positives)*\n",
    "\n",
    "* **High-Rated class** - 92% of the predicted High-Rated instances were actually High-Rated.\n",
    "* **Medium-Rated class** - 96% of the predicted Medium-Rated instances were actually Medium-Rated.\n",
    "* **Low-Rated class** - 84% of the predicted Low-Rated instances were actually Low-Rated.\n",
    "\n",
    "##### Recall\n",
    "*true positives : (true positives + false negatives)*\n",
    "\n",
    "* **High-Rated class** - The model correctly identified 87% of the actual High-Rated instances.\n",
    "* **Medium-Rated class** - The model correctly identified 98% of the actual Medium-Rated instances.\n",
    "* **Low-Rated class** - The model correctly identified 86% of the actual Low-Rated instances.\n",
    "\n",
    "##### F1-score\n",
    "*harmonic mean of precision and recall*\n",
    "\n",
    "* **High-Rated class** - 0.89\n",
    "* **Medium-Rated class** - 0.97\n",
    "* **Low-Rated class** - 0.85\n",
    "\n",
    "##### Support\n",
    "*the number of samples or instances of each class in the test dataset*\n",
    "\n",
    "* **High-Rated class** - 5065\n",
    "* **Medium-Rated class** - 22743\n",
    "* **Low-Rated class** - 1071\n",
    "\n",
    "\n",
    "### <u> Accuracy: 95% </u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7247ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "report(baggingKNN, X_test, Y_test, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6097091f",
   "metadata": {},
   "source": [
    "### Classification report - test set\n",
    "\n",
    "##### Precision: \n",
    "*true positives : (true positives + false positives)*\n",
    "\n",
    "* **High-Rated class** - 85% of the predicted High-Rated instances were actually High-Rated.\n",
    "* **Medium-Rated class** - 95% of the predicted Medium-Rated instances were actually Medium-Rated.\n",
    "* **Low-Rated class** - 74% of the predicted Low-Rated instances were actually Low-Rated.\n",
    "\n",
    "##### Recall\n",
    "*true positives : (true positives + false negatives)*\n",
    "\n",
    "* **High-Rated class** - The model correctly identified 81% of the actual High-Rated instances.\n",
    "* **Medium-Rated class** - The model correctly identified 96% of the actual Medium-Rated instances.\n",
    "* **Low-Rated class** - The model correctly identified 81% of the actual Low-Rated instances.\n",
    "\n",
    "##### F1-score\n",
    "*harmonic mean of precision and recall*\n",
    "\n",
    "* **High-Rated class** - 0.83\n",
    "* **Medium-Rated class** - 0.95\n",
    "* **Low-Rated class** - 0.77\n",
    "\n",
    "##### Support\n",
    "*the number of samples or instances of each class in the test dataset*\n",
    "\n",
    "* **High-Rated class** - 1764\n",
    "* **Medium-Rated class** - 7527\n",
    "* **Low-Rated class** - 336\n",
    "\n",
    "\n",
    "### <u> Accuracy: 92% </u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c298cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "# Class labels\n",
    "labels = ['Low-Rated', 'Medium-Rated', 'High-Rated']  \n",
    "\n",
    "# Create a heatmap for the confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='YlOrRd',\n",
    "            xticklabels=labels, yticklabels=labels)\n",
    "\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf92447",
   "metadata": {},
   "source": [
    "### Confusion matrix\n",
    "\n",
    "##### For the Low-Rated class:\n",
    "* 1427 samples were correctly predicted as Low-Rated\n",
    "* 2 sample was predicted as Medium-Rated but was actually Low-Rated\n",
    "* 335 samples were predicted as High-Rated but were actually Low-Rated\n",
    "\n",
    "##### For the Medium-Rated class:\n",
    "* 4 samples were predicted as Low-Rated but were actually Medium-Rated\n",
    "* 272 samples were correctly predicted as Medium-Rated \n",
    "* 60 samples were predicted as High-Rated but were actually Medium-Rated \n",
    "\n",
    "##### For the High-Rated class:\n",
    "* 243 samples were predicted as Low-Rated but were actually High-Rated\n",
    "* 92 samples were predicted as Medium-Rated but were actually High-Rated\n",
    "* 7192 samples were correctly predicted as High-Rated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19692bd",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cedb736",
   "metadata": {},
   "source": [
    "After training and testing our models, we want to estimate which one solves the classification problem best. Since we can't decide solely based on the model precision, we're going to compare them using the ROC curve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e99a43",
   "metadata": {},
   "source": [
    "## The ROC curve\n",
    "\n",
    "The Receiver Operating Characteristic (ROC) curve is a graphical representation of the trade-off between fpr and tpr. It plots the True Positive Rate (TPR) against the False Positive Rate (FPR) for different classification thresholds.\n",
    "\n",
    "\n",
    "* False Positive Rate (fpr) represents the ratio of the number of false positive predictions to the total number of actual negative samples. It is defined as FP:(FP+TN), where FP is the number of false positives and TN is the number of true negatives.\n",
    "\n",
    "\n",
    "* True Positive Rate (tpr), also known as sensitivity or recall, represents the ratio of the number of true positive predictions to the total number of actual positive samples. It is defined as TP:(TP+FN), where TP is the number of true positives and FN is the number of false negatives.\n",
    "\n",
    "The AUC (Area Under the Curve) is a metric that represents the overall performance of the model in discriminating between positive and negative classes. It measures the area under the ROC curve, with values ranging from 0 to 1, where a score of 0.5 represents a random classifier and a score of 1 represents a perfect classifier.\n",
    "In general, **the higher the AUC, the better the performance of the model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29875786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212f0c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [knn, estimator, baggingKNN]\n",
    "model_names = [\"KNN\", \"GridSearchCV\", \"BaggingClassifier\"]\n",
    "colors = [\"green\", \"blue\", \"red\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1730ccd8",
   "metadata": {},
   "source": [
    "### Low Rated class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1e3ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Low-rated as the positive class\n",
    "pos_class = \"Low-Rated\" \n",
    "\n",
    "# Combine the other two classes into a single negative class\n",
    "neg_class = [\"Medium-Rated\", \"High-Rated\"]\n",
    "\n",
    "# Convert labels to binary format\n",
    "y_train_bin = (Y_train == pos_class).astype(int)\n",
    "y_test_bin = (Y_test == pos_class).astype(int)\n",
    "\n",
    "plt.figure()\n",
    "for model, model_name, color in zip(models, model_names, colors):\n",
    "    # Train a classifier on the training data\n",
    "    model.fit(X_train, y_train_bin)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Compute ROC curve and area under the curve (AUC)\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Plot the ROC curve\n",
    "    plt.plot(fpr, tpr, color=color, lw=2, label= model_name +'(AUC = %0.2f)' % roc_auc)\n",
    "    \n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Low Rated')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe1f07b",
   "metadata": {},
   "source": [
    "### Medium-Rated class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f4384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose Medium-rated as the positive class\n",
    "pos_class = \"Medium-Rated\" \n",
    "# Combine the other two classes into a single negative class\n",
    "neg_class = [\"Low-Rated\", \"High-Rated\"] \n",
    "\n",
    "# Convert labels to binary format\n",
    "y_train_bin = (Y_train == pos_class).astype(int)\n",
    "y_test_bin = (Y_test == pos_class).astype(int)\n",
    "\n",
    "plt.figure()\n",
    "for model, model_name, color in zip(models, model_names, colors):\n",
    "    # Train a classifier on the training data\n",
    "    model.fit(X_train, y_train_bin)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Compute ROC curve and area under the curve (AUC)\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Plot the ROC curve\n",
    "    plt.plot(fpr, tpr, color=color, lw=2, label= model_name +'(AUC = %0.2f)' % roc_auc)\n",
    "    \n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Medium Rated')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077f2fa3",
   "metadata": {},
   "source": [
    "### High-Rated class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978cbe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose High-rated as the positive class\n",
    "pos_class = \"High-Rated\" \n",
    "# Combine the other two classes into a single negative class\n",
    "neg_class = [\"Low-Rated\", \"Medium-Rated\"] \n",
    "\n",
    "# Convert labels to binary format\n",
    "y_train_bin = (Y_train == pos_class).astype(int)\n",
    "y_test_bin = (Y_test == pos_class).astype(int)\n",
    "\n",
    "plt.figure()\n",
    "for model, model_name, color in zip(models, model_names, colors):\n",
    "    # Train a classifier on the training data\n",
    "    model.fit(X_train, y_train_bin)\n",
    "    \n",
    "    # Make predictions on the test data\n",
    "    y_pred = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    # Compute ROC curve and area under the curve (AUC)\n",
    "    fpr, tpr, _ = roc_curve(y_test_bin, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    # Plot the ROC curve\n",
    "    plt.plot(fpr, tpr, color=color, lw=2, label= model_name +'(AUC = %0.2f)' % roc_auc)\n",
    "    \n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - High Rated')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1beef105",
   "metadata": {},
   "source": [
    "Even though GridSearchCV and BaggingClassifier are similar on the Low-Rated instances and have the same AUC, GridSearchCV outperforms it when it comes to Medium and High-Rated classifications.\n",
    "\n",
    "We conclude that GridSearchCV is the most efficient and precise classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7948fb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting the data to other files (decision trees...)\n",
    "import pickle\n",
    "\n",
    "with open('data.pkl', 'wb') as f:\n",
    "    pickle.dump((X_train, X_test, Y_train, Y_test), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
